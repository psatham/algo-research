{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This project analyzes daily stock market data and models their behavior using a Fourier Series to uncover and reconstruct underlying cyclical patterns.\n",
    "\n",
    "### Why use a Fourier Series?\n",
    "\n",
    "The premise is that any curve can be described as a sum of many different sine and cosine waves. What if we take a seemingly random curve, like stock market data, and see if we can recreate it with sine and cosine waves, and use that model to forecast future prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install dependencies quietly, so logs don’t reveal sensitive info like absolute paths or user-specific details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas polygon-api-client matplotlib -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from polygon import RESTClient\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Iterable, Optional, Tuple, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Daily Aggregates\n",
    "\n",
    "Use Polygon.io REST API to get daily aggregated bars. Docs: https://github.com/polygon-io/client-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"<API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = RESTClient(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_daily_aggregates(symbol, start_date, end_date):\n",
    "    aggs = []\n",
    "    for a in client.list_aggs(ticker=symbol, multiplier=1, timespan=\"day\", from_=start_date, to=end_date, limit=50000):\n",
    "        aggs.append(a)\n",
    "    return aggs\n",
    "\n",
    "def get_bars_as_dataframe(aggs):\n",
    "    bars = pd.DataFrame([{\n",
    "        \"timestamp\": a.timestamp,\n",
    "        \"open\": a.open,\n",
    "        \"high\": a.high,\n",
    "        \"low\": a.low,\n",
    "        \"close\": a.close,\n",
    "        \"volume\": a.volume,\n",
    "        \"vwap\": a.vwap,\n",
    "        \"transactions\": a.transactions\n",
    "    } for a in aggs])\n",
    "\n",
    "    # Convert timestamp to datetime and set as index\n",
    "    bars[\"date\"] = pd.to_datetime(bars[\"timestamp\"], unit=\"ms\")\n",
    "    bars.set_index(\"date\", inplace=True)\n",
    "    bars.drop(columns=[\"timestamp\"], inplace=True)\n",
    "\n",
    "    return bars.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Raw Stock Market Data\n",
    "\n",
    "Let's say $y(t)$ represents our sample stock market data, where it is a function of time $t$. We want to create $\\hat{y}(t)$, trained on the data from $y(t)$, that closely resembles the original function while being modeled using a Fourier Series. This will enable us to input any time $t$ into $\\hat{y}(t)$ so that we can forecast prices that exist outside of the current time domain.\n",
    "\n",
    "$$\n",
    "y(t) \\;\\rightarrow\\; \\text{sample stock market data}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y}(t) =\n",
    "\\underbrace{a + bt}_{\\text{linear drift}}\n",
    "+\n",
    "\\underbrace{\\sum_{k=0}^{K-1}\\big(c_k\\cos(\\omega_k t) + d_k\\sin(\\omega_k t)\\big)}_{\\text{oscillation}}\n",
    "$$\n",
    "\n",
    "where $a$ is the slope intercept, $b$ is the slope, $c_k$ is the coefficient for the $\\cos(\\omega_k t)$ component, $d_k$ is the coefficient for the $\\sin(\\omega_k t)$ component, $\\omega_k$ is the angular frequency, and $K$ is the number of frequencies included in the model.\n",
    "\n",
    "Note that $\\hat{y}(t)$ has a linear drift component as well as an oscillation component. In the real world, stock prices can trend upwards or downwards, captured by the linear slope $b$; and at $t=0$, the stock price may start at a non-zero number, hence the reason we offset with the value $a$. We will remove this linear drift component from a piece of our data when calculating the dominant angular frequencies (an intermediate step expanded below), but it's important to recognize that linear drift is still a part of our final resulting function.\n",
    "\n",
    "In order to create $\\hat{y}(t)$, we can break it down into four steps, at a high-level:\n",
    "\n",
    "1. **Prepare time series** - initialize sample data based on closing price\n",
    "\n",
    "2. **Calculate dominant angular frequencies** - this basically tells us where the strongest sinuisoidal waves exist in our data\n",
    "\n",
    "3. **Build design matrix** - creating a table that tells us how each of these waves combine at each point in time\n",
    "\n",
    "4. **Ridge regression** - use ridge regression fit to find the smoothest mix of waves that match the stock market data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Time Series\n",
    "\n",
    "#### A. Initialize Sample Data on Closing Price\n",
    "\n",
    "We can use the closing price on each trading day to model our Fourier Series. By taking the logarithm of the closing price, we convert multiplicative changes into additive ones, which stabilizes variance and makes the changes comparable across different price levels. We will represent our sample data as $y(t)$, where it is a function of $t = 0, 1, 2, \\dots, N-1$, and $N$ is the number of samples.\n",
    "\n",
    "e.g.\n",
    "\n",
    "$$\n",
    "\\text{Stock A: } \\$5 \\rightarrow \\$10,\\ +5\\ \\text{change}\n",
    "$$\n",
    "$$\n",
    "\\text{Stock B: } \\$100 \\rightarrow \\$105,\\ +5\\ \\text{change}\n",
    "$$\n",
    "$$\n",
    "\\text{Stock A: } \\log(5) \\approx 0.6990 \\rightarrow \\log(10) = 1,\\ +0.3010\\ \\text{change}\n",
    "$$\n",
    "$$\n",
    "\\text{Stock B: } \\log(100) = 2 \\rightarrow \\log(105) \\approx 2.0212,\\ +0.0212\\ \\text{change}\n",
    "$$\n",
    "\n",
    "Even though Stock A and B both changed by +5, a move from \\$5→\\$10 (100% increase) is very different from a move \\$100→\\$105 (5% increase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_series(\n",
    "    bars: pd.DataFrame,\n",
    "    use_log: bool = True\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # Initilize the time series y and its time index t -> sample data: y(t)\n",
    "    y = bars['close'].astype(float).to_numpy()\n",
    "    y = np.log(y) if use_log else y\n",
    "    t = np.arange(len(y), dtype=float)\n",
    "    \n",
    "    return y, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate Dominant Angular Frequencies\n",
    "\n",
    "#### A. Detrend\n",
    "\n",
    "Let's say that our sample data $ y(t) $ has a linear drift. We want to remove the linear drift component before calculating the top angular frequencies, because the Fourier transform will interpret even a slight linear drift as a very slow wave. Let's create a new function called $ \\tilde{y}(t) $, so we don't modify the original sample data.\n",
    "\n",
    "$$\n",
    "y(t) \\approx a + bt\n",
    "$$\n",
    "\n",
    "where $ a $ is the slope intercept and $ b $ is the slope\n",
    "\n",
    "$$\n",
    "\\tilde{y}(t) = y(t) - (a + bt)\n",
    "$$\n",
    "\n",
    "$a + bt$ can also be represented as the matrix multiplication of $A$ and $\\beta$, where\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & t_0 \\\\\n",
    "1 & t_1 \\\\\n",
    "1 & t_2 \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "1 & t_{N-1}\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "\\beta =\n",
    "\\begin{bmatrix}\n",
    "a \\\\\n",
    "b\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a + bt = A\\beta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{y}(t) = y(t) - A\\beta\n",
    "$$\n",
    "\n",
    "We want to solve for the best $\\beta$ using the least squares loss function to find the best linear fit, which we will denote $\\beta^*$.\n",
    "\n",
    "$$\n",
    "\\text{find } \\beta \\text{ such that } y \\approx A\\beta \\rightarrow \\beta^*\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta^* = \\arg\\min_{\\beta} \\lVert y - A\\beta \\rVert^2\n",
    "$$\n",
    "\n",
    "$L(\\beta)$ is the least squares loss function. We're going to solve the first derivative and second derivative of $L$ to get $\\beta^*$.\n",
    "\n",
    "$$\n",
    "L(\\beta) = \\lVert y - A\\beta \\rVert^2\n",
    "$$\n",
    "\n",
    "Aside: $\\lVert y - A\\beta \\rVert = \\sqrt{(y - A\\beta)^2}$  \n",
    "therefore $\\lVert y - A\\beta \\rVert^2 = (y - A\\beta)^2$\n",
    "\n",
    "$$\n",
    "= (y - A\\beta)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (y - A\\beta)^T (y - A\\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= y^Ty - y^TA\\beta - y\\beta^TA^T + \\beta^TA^TA\\beta\n",
    "$$\n",
    "\n",
    "Aside: $y^TA\\beta = \\beta^TA^Ty$  \n",
    "therefore $-y^TA\\beta - y\\beta^TA^T = -2\\,\\beta^TA^Ty$\n",
    "\n",
    "$$\n",
    "= y^Ty - 2\\,\\beta^TA^Ty + \\beta^TA^TA\\beta\n",
    "$$\n",
    "\n",
    "Aside: \n",
    "$\\frac{d}{d\\beta}(\\beta^T A^T A \\beta)\n",
    "=\n",
    "(A^T A + (A^T A)^T)\\beta\n",
    "=\n",
    "(A^T A + A^T A)\\beta\n",
    "=\n",
    "2A^T A\\beta$\n",
    "\n",
    "$$\n",
    "\\frac{dL}{d\\beta} = 0 - 2A^Ty + 2A^TA\\beta\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d^2L}{d\\beta^2} = 0 + 0 + 2A^TA\n",
    "$$\n",
    "\n",
    "$\\frac{dL}{d\\beta} = 0$ indicates a global minimum when $\\frac{d^2L}{d\\beta^2}$ (aka the Hessian) is positive definite. We just need to prove that $A^TA$ is positive definite (ignoring the coefficient 2), which is true if and only if $A^TA$ is invertible.\n",
    "\n",
    "$A^TA$ is a square matrix where all the columns of $A$ are linearly independent - not multiples of each other. Likewise, the columns of $A^TA$ are also linearly independent, therefore $A^TA$ is invertible.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A^TA &=\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=0}^{N-1} 1 & \\sum_{i=0}^{N-1} t_i \\\\\n",
    "\\sum_{i=0}^{N-1} t_i & \\sum_{i=0}^{N-1} t_i^2\n",
    "\\end{bmatrix}\n",
    "\\\\[8pt]\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "N & \\sum_{i=0}^{N-1} t_i \\\\\n",
    "\\sum_{i=0}^{N-1} t_i & \\sum_{i=0}^{N-1} t_i^2\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since $A^TA$ is invertible and $\\frac{d^2L}{d\\beta^2}$ is positive definite, $\\beta^*$ is the $\\beta$ where $\\frac{dL}{d\\beta} = 0$.\n",
    "\n",
    "$$\n",
    "0 = -2A^Ty + 2A^TA\\beta^*\n",
    "$$\n",
    "\n",
    "$$\n",
    "-2A^TA\\beta^* = -2A^Ty\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^TA\\beta^* = A^Ty\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta^* = (A^TA)^{-1} A^Ty\n",
    "$$\n",
    "\n",
    "We can use numpy to solve for $\\beta^*$, i.e.\n",
    "\n",
    "```python\n",
    "beta = numpy.linalg.solve(ATA, ATy)\n",
    "```\n",
    "\n",
    "Just for fun, we can expand the matrix multiplication for $\\beta^*$, which sheds some light on what numpy is doing under the hood.\n",
    "\n",
    "Aside: for a $2\\times 2$ matrix,  \n",
    "$\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix}^{-1}\n",
    "=\n",
    "\\frac{1}{ad - bc}\n",
    "\\begin{bmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$$\n",
    "(A^TA)^{-1}\n",
    "=\n",
    "\\frac{1}{\\,N\\sum_{i=0}^{N-1} t_i^2 - \\left(\\sum_{i=0}^{N-1} t_i\\right)^2\\,}\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=0}^{N-1} t_i^2 & -\\sum_{i=0}^{N-1} t_i \\\\\n",
    "-\\sum_{i=0}^{N-1} t_i & N\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^Ty\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=0}^{N-1} y_i \\\\\n",
    "\\sum_{i=0}^{N-1} t_i y_i\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta^*\n",
    "=\n",
    "(A^TA)^{-1}A^Ty\n",
    "=\n",
    "\\frac{1}{\\,N\\sum_{i=0}^{N-1} t_i^2 - \\left(\\sum_{i=0}^{N-1} t_i\\right)^2\\,}\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=0}^{N-1} t_i^2 & -\\sum_{i=0}^{N-1} t_i \\\\\n",
    "-\\sum_{i=0}^{N-1} t_i & N\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\sum_{i=0}^{N-1} y_i \\\\\n",
    "\\sum_{i=0}^{N-1} t_i y_i\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta^*\n",
    "=\n",
    "\\frac{1}{\\,N\\sum_{i=0}^{N-1} t_i^2 - \\left(\\sum_{i=0}^{N-1} t_i\\right)^2\\,}\n",
    "\\begin{bmatrix}\n",
    "\\left(\\sum_{i=0}^{N-1} t_i^2\\right)\\left(\\sum_{i=0}^{N-1} y_i\\right)\n",
    "-\n",
    "\\left(\\sum_{i=0}^{N-1} t_i\\right)\\left(\\sum_{i=0}^{N-1} t_i y_i\\right)\n",
    "\\\\\n",
    "-\\left(\\sum_{i=0}^{N-1} t_i\\right)\\left(\\sum_{i=0}^{N-1} y_i\\right)\n",
    "+\n",
    "N\\left(\\sum_{i=0}^{N-1} t_i y_i\\right)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### B. Hann Window\n",
    "\n",
    "A Hann window is a smoothing function applied to our sample data before taking its Fourier transform to reduce the sharp discontinuities at its boundaries. By softening these boundaries, we reduce spectral leakage and keep our frequency components more concentrated around their true values.\n",
    "\n",
    "$$\n",
    "h(n) = \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{2\\pi n}{N-1}\\right)\\right)\n",
    "\\quad n = [0, N-1]\n",
    "$$\n",
    "\n",
    "$$\n",
    "h(0) = h(N-1) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{y} \\;\\Rightarrow\\; h\\,\\tilde{y}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### C. Real Fast Fourier Transform (RFFT)\n",
    "\n",
    "We convert the time-domain signal $\\tilde{y}(t)$ into the frequency domain using the Discrete Fourier Transform (computed efficiently via the RFFT) to extract dominant angular frequencies $\\omega_k$.\n",
    "\n",
    "$$\n",
    "S(k) = \\sum_{n=0}^{N-1} \\tilde{y}(n) \\, e^{-j\\, 2\\pi \\frac{kn}{N}}\n",
    "$$\n",
    "\n",
    "where $S(k)$ is the complex DFT coefficient at frequency bin $k$, $N$ is the number of samples, and $j$ is the imaginary unit $\\sqrt{-1}$. \n",
    "\n",
    "Because $\\tilde{y}(t)$ is real-valued, the DFT satisfies the Hermitian symmetry $S(k) = \\overline{S(N-k)}$, meaning the spectrum is mirrored and only the first $\\left\\lfloor \\tfrac{N}{2} \\right\\rfloor + 1$ coefficients contain unique frequency information. \n",
    "\n",
    "The magnitude $|S(k)|$ represents the strength of the component at angular frequency $\\omega_k$.\n",
    "\n",
    "$$\n",
    "\\omega_k = 2\\pi \\frac{k}{N}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y}(t) =\n",
    "a + bt +\n",
    "\\sum_{k=0}^{K-1}\n",
    "\\big(c_k \\cos(\\omega_k t) + d_k \\sin(\\omega_k t)\\big)\n",
    "$$\n",
    "\n",
    "where $K = \\left\\lfloor \\tfrac{N}{2} \\right\\rfloor + 1$, the number of frequencies selected from the RFFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dominant_angular_frequencies(\n",
    "    y: np.ndarray,\n",
    "    t: np.ndarray,\n",
    "    use_detrend: bool = True,\n",
    "    use_hann: bool = True,\n",
    "    sample_spacing: float = 1.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # If sampled data is too small, return\n",
    "    N = y.size\n",
    "    if N < 2:\n",
    "        return np.array([], dtype=float), np.array([], dtype=float)\n",
    "\n",
    "    y_tilda = y.copy()\n",
    "\n",
    "    # (A) Detrend\n",
    "    if use_detrend:\n",
    "        A = np.column_stack([np.ones_like(t), t])\n",
    "        ATA = A.T @ A\n",
    "        ATy = A.T @ y\n",
    "        beta = np.linalg.solve(ATA, ATy)\n",
    "        y_tilda = y - (A @ beta)\n",
    "\n",
    "    # (B) Hann window\n",
    "    if use_hann:\n",
    "        y_tilda = y_tilda * np.hanning(N)\n",
    "\n",
    "    # (C) Fast Fourier Transform (FFT)\n",
    "    S = np.fft.rfft(y_tilda)                              \n",
    "    freqs = np.fft.rfftfreq(N, d=sample_spacing)     \n",
    "    magnitudes = np.abs(S)                                \n",
    "    omegas = 2.0 * np.pi * freqs\n",
    "    \n",
    "    return omegas, magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Design Matrix\n",
    "\n",
    "We construct the design matrix $X$ as:\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "1 & t_0 & \\cos(\\omega_0 t_0) & \\sin(\\omega_0 t_0) & \\cdots & \\cos(\\omega_{K-1} t_0) & \\sin(\\omega_{K-1} t_0) \\\\\n",
    "1 & t_1 & \\cos(\\omega_0 t_1) & \\sin(\\omega_0 t_1) & \\cdots & \\cos(\\omega_{K-1} t_1) & \\sin(\\omega_{K-1} t_1) \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "1 & t_{N-1} & \\cos(\\omega_0 t_{N-1}) & \\sin(\\omega_0 t_{N-1}) & \\cdots & \\cos(\\omega_{K-1} t_{N-1}) & \\sin(\\omega_{K-1} t_{N-1})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Note that the first two columns correspond to the linear drift component in $\\hat{y}$, and the following columns correspond to the oscillation component. \n",
    "\n",
    "In the Ridge Regression step, we will use the design matrix $X$ to calculate $\\theta$ such that $\\hat{y} = X \\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_design_matrix(\n",
    "    t: np.ndarray,\n",
    "    omegas: np.ndarray,\n",
    "    include_linear_drift: bool = True\n",
    ") -> np.ndarray:\n",
    "    cols = []\n",
    "    \n",
    "    if include_linear_drift:\n",
    "        cols.append(np.ones_like(t, dtype=float))\n",
    "        cols.append(t.astype(float))\n",
    "        \n",
    "    for w in omegas:\n",
    "        cols.append(np.cos(w * t))\n",
    "        cols.append(np.sin(w * t))\n",
    "    \n",
    "    X = np.column_stack(cols).astype(float)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ridge Regression\n",
    "\n",
    "We can write our model in matrix form as $\\hat{y} = X\\theta$, where\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "1 & t_0 & \\cos(\\omega_0 t_0) & \\sin(\\omega_0 t_0) & \\cdots & \\cos(\\omega_{K-1} t_0) & \\sin(\\omega_{K-1} t_0) \\\\\n",
    "1 & t_1 & \\cos(\\omega_0 t_1) & \\sin(\\omega_0 t_1) & \\cdots & \\cos(\\omega_{K-1} t_1) & \\sin(\\omega_{K-1} t_1) \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "1 & t_{N-1} & \\cos(\\omega_0 t_{N-1}) & \\sin(\\omega_0 t_{N-1}) & \\cdots & \\cos(\\omega_{K-1} t_{N-1}) & \\sin(\\omega_{K-1} t_{N-1})\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "\\theta =\n",
    "\\begin{bmatrix}\n",
    "a \\\\\n",
    "b \\\\\n",
    "c_0 \\\\\n",
    "d_0 \\\\\n",
    "\\vdots \\\\\n",
    "c_{K-1} \\\\\n",
    "d_{K-1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{bmatrix}\n",
    "\\hat{y}(t_0) \\\\\n",
    "\\hat{y}(t_1) \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}(t_{N-1})\n",
    "\\end{bmatrix}\n",
    "=\n",
    "a + bt + \\sum_{k=0}^{K-1}\\big(c_k\\cos(\\omega_k t) + d_k\\sin(\\omega_k t)\\big)\n",
    "$$\n",
    "\n",
    "We want to solve for the best $\\theta$ using the least squares loss function with ridge regularization, which we will denote $\\theta^*$.\n",
    "\n",
    "$$\n",
    "\\text{find }\\theta\\text{ such that } y \\approx X\\theta \\;\\rightarrow\\; \\theta^*\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_{\\theta}\\left(\\lVert y - X\\theta\\rVert^2 + \\alpha\\lVert\\theta\\rVert^2\\right)\n",
    "$$\n",
    "\n",
    "Note that this process is very similar to how we solved for $\\beta^*$ for $y \\approx A\\beta$, except for one key difference — the ridge penalty $\\alpha\\lVert\\theta\\rVert^2$. We introduce $\\alpha\\lVert\\theta\\rVert^2$ to make the problem well-posed when the columns of $X$ are correlated.\n",
    "\n",
    "Recall that for a simple linear drift model,\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & t_0 \\\\\n",
    "1 & t_1 \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "1 & t_{N-1}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "the two columns $1$ and $t$ are completely independent and will never be correlated.\n",
    "\n",
    "However, for the design matrix X, there is a possibility that some of the oscillation components could be correlated, which would cause the coefficients in $\\theta$ to become large and unstable.\n",
    "\n",
    "The ridge penalty $\\alpha\\lVert\\theta\\rVert^2$ shrinks these coefficients towards zero, especially important for the $c_k$ and $d_k$ terms, in order to make the fit more robust.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    alpha: float = 0.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "    # Ridge Regression\n",
    "    XTXa = X.T @ X + alpha * np.eye(X.shape[1])\n",
    "    XTy = X.T @ y\n",
    "    theta = np.linalg.solve(XTXa, XTy)\n",
    "    y_hat = X @ theta\n",
    "    \n",
    "    return theta, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m omegas, frequencies = calculate_dominant_angular_frequencies(y, t)\n\u001b[32m     10\u001b[39m X = build_design_matrix(t, omegas)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m theta, y_hat = \u001b[43mridge_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(bars[:-\u001b[32m10\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mridge_regression\u001b[39m\u001b[34m(X, y, alpha)\u001b[39m\n\u001b[32m      8\u001b[39m XTXa = X.T @ X + alpha * np.eye(X.shape[\u001b[32m1\u001b[39m])\n\u001b[32m      9\u001b[39m XTy = X.T @ y\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m theta = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXTXa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXTy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m y_hat = X @ theta\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m theta, y_hat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/pipx/venvs/jupyter/lib/python3.13/site-packages/numpy/linalg/_linalg.py:471\u001b[39m, in \u001b[36msolve\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m    468\u001b[39m signature = \u001b[33m'\u001b[39m\u001b[33mDD->D\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdd->d\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call=_raise_linalgerror_singular, invalid=\u001b[33m'\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    470\u001b[39m               over=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, divide=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, under=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     r = \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r.astype(result_t, copy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/pipx/venvs/jupyter/lib/python3.13/site-packages/numpy/linalg/_linalg.py:163\u001b[39m, in \u001b[36m_raise_linalgerror_singular\u001b[39m\u001b[34m(err, flag)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33m\"\u001b[39m\u001b[33mSingular matrix\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mLinAlgError\u001b[39m: Singular matrix"
     ]
    }
   ],
   "source": [
    "symbol = \"NVDA\"\n",
    "\n",
    "bars_start_date, bars_end_date = \"2025-01-01\", \"2025-09-30\"\n",
    "    \n",
    "aggs = list_daily_aggregates(symbol, bars_start_date, bars_end_date)\n",
    "bars = get_bars_as_dataframe(aggs)\n",
    "\n",
    "y, t = prepare_time_series(bars)\n",
    "omegas, frequencies = calculate_dominant_angular_frequencies(y, t)\n",
    "X = build_design_matrix(t, omegas)\n",
    "theta, y_hat = ridge_regression(X, y)\n",
    "\n",
    "print(bars[:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
